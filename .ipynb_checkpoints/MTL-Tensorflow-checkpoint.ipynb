{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 100)\n",
      "(1000, 100)\n",
      "(1000, 100)\n",
      "(8000, 1)\n",
      "(8000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(8000, 2)\n",
      "(1000, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "#from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "#from tensorboardX import SummaryWriter\n",
    "#import seaborn as sns\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "#from sklearn.linear_model import Ridge\n",
    "#from sklearn.linear_model import RidgeCV\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "N = 10000\n",
    "M = 100\n",
    "c = 0.5\n",
    "p = 0.9\n",
    "k = np.random.randn(M)\n",
    "u1 = np.random.randn(M)\n",
    "u1 -= u1.dot(k) * k / np.linalg.norm(k)**2\n",
    "u1 /= np.linalg.norm(u1) \n",
    "k /= np.linalg.norm(k) \n",
    "u2 = k\n",
    "w1 = c*u1\n",
    "w2 = c*(p*u1+np.sqrt((1-p**2))*u2)\n",
    "X = np.random.normal(0, 1, (N, M))\n",
    "eps1 = np.random.normal(0, 0.01)\n",
    "eps2 = np.random.normal(0, 0.01)\n",
    "Y1 = np.matmul(X, w1) + np.sin(np.matmul(X, w1))+eps1\n",
    "Y2 = np.matmul(X, w2) + np.sin(np.matmul(X, w2))+eps2\n",
    "split = list(np.random.permutation(N))\n",
    "\n",
    "X_train = X[split[0:8000],:]\n",
    "Y1_train = Y1[split[0:8000]].reshape(-1,1)\n",
    "Y2_train = Y2[split[0:8000]].reshape(-1,1)\n",
    "X_valid = X[8000:9000,:]\n",
    "Y1_valid = Y1[8000:9000].reshape(-1,1)\n",
    "Y2_valid = Y2[8000:9000].reshape(-1,1)\n",
    "X_test = X[9000:10000,:]\n",
    "Y1_test = Y1[9000:10000].reshape(-1,1)\n",
    "Y2_test = Y2[9000:10000].reshape(-1,1)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y1_train.shape)\n",
    "print(Y2_train.shape)\n",
    "print(Y1_valid.shape)\n",
    "print(Y2_valid.shape)\n",
    "print(Y1_test.shape)\n",
    "print(Y2_test.shape)\n",
    "Y_train = np.concatenate((Y1_train.reshape(-1,1), Y2_train.reshape(-1,1)), axis=1)\n",
    "Y_valid = np.concatenate((Y1_valid.reshape(-1,1), Y2_valid.reshape(-1,1)), axis=1)\n",
    "Y_test = np.concatenate((Y1_test.reshape(-1,1), Y2_test.reshape(-1,1)), axis=1)\n",
    "print(Y_train.shape)\n",
    "print(Y_valid.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-74f3705ad12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gene\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "mb_size = 100\n",
    "n_shared = 64\n",
    "n_hidden1 = 32\n",
    "n_hidden2 = 16\n",
    "num_epochs = 50\n",
    "#keep_prob = 1\n",
    "n_output = 1\n",
    "\n",
    "def PlaceHolder(dims):\n",
    "    PH = tf.placeholder(tf.float32, [None, dims])\n",
    "    return PH \n",
    "\n",
    "def Shared_layer(dat, keep_prob):\n",
    "\n",
    "    H1 = tf.layers.dense(inputs=dat, units=n_shared, activation=tf.nn.relu)\n",
    "    Drop_H1 = tf.nn.dropout(H1, keep_prob)\n",
    "    #bn_Drop_H1 = tf.contrib.layers.batch_norm(Drop_H1, center =True, scale = True)    \n",
    "\n",
    "    return Drop_H1\n",
    "\n",
    "def Tower_layer1(dat, keep_prob):\n",
    "\n",
    "    H1_1 = tf.layers.dense(inputs=dat, units=n_hidden1, activation=tf.nn.relu)\n",
    "    Drop_H1_1 = tf.nn.dropout(H1_1, keep_prob)\n",
    "    #bn_Drop_H1 = tf.contrib.layers.batch_norm(Drop_H1, center =True, scale = True)\n",
    "\n",
    "    H2_1 = tf.layers.dense(inputs=Drop_H1_1, units=n_hidden2, activation=tf.nn.relu)\n",
    "    Drop_H2_1 = tf.nn.dropout(H2_1, keep_prob)\n",
    "    #bn_Drop_H2 = tf.contrib.layers.batch_norm(Drop_H2, center =True, scale = True)\n",
    "\n",
    "    H3_1 = tf.layers.dense(inputs=Drop_H2_1, units=n_output)\n",
    "\n",
    "    return H3_1\n",
    "\n",
    "def Tower_layer2(dat, keep_prob):\n",
    "\n",
    "    H1_2 = tf.layers.dense(inputs=dat, units=n_hidden1, activation=tf.nn.relu)\n",
    "    Drop_H1_2 = tf.nn.dropout(H1_2, keep_prob)\n",
    "    #bn_Drop_H1 = tf.contrib.layers.batch_norm(Drop_H1, center =True, scale = True)\n",
    "\n",
    "    H2_2 = tf.layers.dense(inputs=Drop_H1_2, units=n_hidden2, activation=tf.nn.relu)\n",
    "    Drop_H2_2 = tf.nn.dropout(H2_2, keep_prob)\n",
    "    #bn_Drop_H2 = tf.contrib.layers.batch_norm(Drop_H2, center =True, scale = True)\n",
    "\n",
    "    H3_2 = tf.layers.dense(inputs=Drop_H2_2, units=n_output)\n",
    "\n",
    "    return H3_2\n",
    "\n",
    "def compute_cost(Y_pred, Y_true):\n",
    "\n",
    "    Logits = Y_pred\n",
    "    Labels = Y_true \n",
    "    #Labels = tf.reshape(Labels, [-1,1])\n",
    "    Loss = tf.losses.mean_squared_error(Labels, Logits)\n",
    "    cost = tf.reduce_mean(Loss)       \n",
    "    return cost\n",
    "\n",
    "def random_mini_batches(XE, R1E, R2E, mini_batch_size = 10, seed = 42): \n",
    "    # Creating the mini-batches\n",
    "    np.random.seed(seed)            \n",
    "    m = XE.shape[0]                  \n",
    "    mini_batches = []\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_XE = XE[permutation,:]\n",
    "    shuffled_X1R = R1E[permutation]\n",
    "    shuffled_X2R = R2E[permutation]\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    for k in range(0, int(num_complete_minibatches)):\n",
    "        mini_batch_XE = shuffled_XE[k * mini_batch_size : (k+1) * mini_batch_size, :]\n",
    "        mini_batch_X1R = shuffled_X1R[k * mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch_X2R = shuffled_X2R[k * mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_XE, mini_batch_X1R, mini_batch_X2R)\n",
    "        mini_batches.append(mini_batch)\n",
    "    Lower = int(num_complete_minibatches * mini_batch_size)\n",
    "    Upper = int(m - (mini_batch_size * math.floor(m/mini_batch_size)))\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_XE = shuffled_XE[Lower : Lower + Upper, :]\n",
    "        mini_batch_X1R = shuffled_X1R[Lower : Lower + Upper]\n",
    "        mini_batch_X2R = shuffled_X2R[Lower : Lower + Upper]\n",
    "        mini_batch = (mini_batch_XE, mini_batch_X1R, mini_batch_X2R)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "seed = 42 \n",
    "tf.set_random_seed(seed)    \n",
    "(n_samp, n_gene) = X_train.shape\n",
    "(n_samp, n_out) = Y_train.shape\n",
    "cost1tr = []\n",
    "cost2tr = []\n",
    "cost1D = []\n",
    "cost2D = []\n",
    "cost1ts = []\n",
    "cost2ts = []\n",
    "costtr = []\n",
    "costD = []\n",
    "costts = []\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = PlaceHolder(n_gene)\n",
    "Y1 = PlaceHolder(n_output)\n",
    "Y2 = PlaceHolder(n_output)\n",
    "kp = tf.placeholder(tf.float32)\n",
    "\n",
    "H_shared = Shared_layer(X, kp)\n",
    "H1 = Tower_layer1(H_shared, kp)\n",
    "H2 = Tower_layer2(H_shared, kp)\n",
    "        \n",
    "cost1 = compute_cost(H1, Y1)\n",
    "cost2 = compute_cost(H2, Y2)\n",
    "\n",
    "cost = tf.divide(tf.add(cost1, cost2), 2)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:       \n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_cost = 0  \n",
    "        epoch_cost1 = 0\n",
    "        epoch_cost2 = 0\n",
    "        \n",
    "        num_minibatches = int(n_samp / mb_size) \n",
    "        minibatches = random_mini_batches(X_train, Y1_train, Y2_train, mb_size, seed)\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "            (mb_X, mb_Y1, mb_Y2) = minibatch\n",
    "            _ , minibatch_cost= sess.run([optimizer, cost], feed_dict={X: mb_X, Y1: mb_Y1, Y2: mb_Y2, kp: 0.5})\n",
    "            epoch_cost = epoch_cost + (minibatch_cost / num_minibatches)\n",
    "            \n",
    "            mb_cost1 = sess.run(cost1, feed_dict={X: mb_X, Y1: mb_Y1, Y2: mb_Y2, kp: 0.5})\n",
    "            epoch_cost1 = epoch_cost1 + (mb_cost1 / num_minibatches)\n",
    "            \n",
    "            mb_cost2 = sess.run(cost2, feed_dict={X: mb_X, Y1: mb_Y1, Y2: mb_Y2, kp: 0.5})\n",
    "            epoch_cost2 = epoch_cost2 + (mb_cost2 / num_minibatches)\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch: %d, Train Cost: %5.3f ' % (epoch, epoch_cost))\n",
    "            dv_cost = sess.run(cost, feed_dict={X: X_valid, Y1: Y1_valid, Y2: Y2_valid, kp: 0.5})\n",
    "            dv_cost1 = sess.run(cost1, feed_dict={X: X_valid, Y1: Y1_valid, Y2: Y2_valid, kp: 0.5})\n",
    "            cost1D.append(dv_cost1)\n",
    "            dv_cost2 = sess.run(cost2, feed_dict={X: X_valid, Y1: Y1_valid, Y2: Y2_valid, kp: 0.5})\n",
    "            cost2D.append(dv_cost2)\n",
    "            #dv_cost = (dv_cost1+dv_cost2)/2\n",
    "\n",
    "            print('Epoch: %d, Dev Cost: %5.3f ' % (epoch, dv_cost))\n",
    "        costtr.append(np.mean(epoch_cost))\n",
    "        cost1tr.append(np.mean(epoch_cost1))\n",
    "        cost2tr.append(np.mean(epoch_cost2))\n",
    "        costD.append(dv_cost)\n",
    "\n",
    "plt.plot(np.squeeze(costtr),'-r',np.squeeze(costD), '-b')\n",
    "plt.ylabel('total cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.squeeze(cost1tr), '-r', np.squeeze(cost1D), '-b')\n",
    "plt.ylabel('task 1 cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.show() \n",
    "\n",
    "plt.plot(np.squeeze(cost2tr),'-r', np.squeeze(cost2D),'-b')\n",
    "plt.ylabel('task 2 cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (DeepCTR)",
   "language": "python",
   "name": "pycharm-66b6ae02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
